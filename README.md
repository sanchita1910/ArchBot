# ArchBot
ArchBot is a lightweight, three-tier LLM portal powered by Ollama. It provides:  âœ“ Real-time streaming chat (SSE) âœ“ Persistent sessions âœ“ Session-level system prompts âœ“ Intelligent SHA-256 caching with TTL âœ“ Admin dashboard for monitoring âœ“ Dockerized deployment (Frontend + Backend + Ollama)

## Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚     â”‚    Backend      â”‚     â”‚     Ollama      â”‚
â”‚    (NGINX)      â”‚â—„â”€â”€â”€â”€â”¤   (Node.js)     â”‚â—„â”€â”€â”€â”€â”¤   (Llama 3.2)   â”‚
â”‚   Port: 3000    â”‚     â”‚   Port: 3001    â”‚     â”‚   Port: 11434   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
## Architectural Patterns

Repository Pattern â€” Abstracted session + cache access
Adapter Pattern â€” Model-agnostic integration layer
Middleware Pattern â€” Logging, rate limiting, auth, error handling
Cache-Aside Pattern â€” SHA-256 keys + TTL
Service Layer â€” Encapsulated business logic

## Quick Start
1ï¸âƒ£ Start All Services
docker compose up -d --build

2ï¸âƒ£ Pull the Required LLM Model
docker exec -it ollama ollama pull llama3.2

ğŸŒ Access the Application
Component	URL
Chat Portal	http://localhost:3000

Admin Dashboard	http://localhost:3000/admin.html

Default Admin Credentials

Username: admin

Password: csci578

ğŸ›‘ Stop All Services
docker compose down

## Project Structure
pocketllm/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.js              # Express backend (SSE + caching)
â”‚   â”œâ”€â”€ Dockerfile             # Backend container
â”‚   â”œâ”€â”€ package.json
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html             # Chat interface
â”‚   â”œâ”€â”€ admin.html             # Admin dashboard
â”‚   â”œâ”€â”€ Dockerfile             # NGINX container
â”‚
â”œâ”€â”€ docker-compose.yml         # Service orchestration
â””â”€â”€ README.md

## Container Services
1. Ollama (ollama)

Image: ollama/ollama:latest

Port: 11434

Purpose: Runs the Llama 3.2 LLM

2. Backend (pocketllm-backend)

Base Image: node:18-alpine

Port: 3001

Environment:

OLLAMA_HOST=http://ollama:11434
OLLAMA_MODEL=llama3.2
CACHE_TTL_MS=600000
PORT=3001

3. Frontend (pocketllm-frontend)

Base Image: nginx:alpine

Port: 3000

Purpose: Serves static HTML/CSS/JS
